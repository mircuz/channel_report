\chapter{Conclusions \& Further Works}

I am glad to say that we have reached our original goal to provide a scalable DNS solver through the usage of the MPI technology. \par
At present time the code lacks in an intra-nodal effectively parallelization, therefore its performances are limited by the MPI local communication performance. Despite of this the code revealed to be robust, being capable of working both with small datasets then extra large ones, exhibiting a linear gain in terms of productivity.
The possibility to perform live post-processing of the data, instead of writing them, allows to save terabytes of memory, allowing the code to run also on networks of commodity hardware. \\~\par
The fundamental restriction imposed by the original code about the number of parallel tasks has been removed, bringing the theoretical number of parallel processes to be limited by the product of $nx \times nz$ modes. \\~\par
The engine developed is flexible and since is not affected by the geometry of the problem could be adapted quickly to carry out boundary layers simulations, just by imposing different boundary conditions, or can be used to solve pipe flows simulations.\\~\par

The intent of this work was just to provide a study of feasibility for a solver based on pencil decomposition approach relying on inter-nodal parallelization, therefore we are satisfied by the results obtained. It should be denoted that, at present time, we cannot consider this as a ``completed'' solver. The lack of a dedicated shared memory parallelization reduce the efficiency significantly. However, we would like to highlight that a dedicated shared memory parallelization could be carried out just by changing few rows, without the needing of a significant reworking of the code.
With today tendency of the HPC processors to increase the number of threads, instead of the number of physical CPU, this evolution, towards the so called \emph{hybrid-programming}, seems mandatory.
